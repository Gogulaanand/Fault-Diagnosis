{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "df=pd.read_csv('projdata.csv',encoding = \"utf-8\",engine='python',sep=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GOGULAANAND\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "y=np.array(df[['Fault']])\n",
    "X=df.as_matrix(columns=df.columns[1:])\n",
    "X=X.T\n",
    "y=y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3287)\n",
      "Size of input layer: 3\n",
      "Size of output layer: 1\n",
      "Size of hidden units in each layer: 3\n",
      "No of hidden layers: 2\n"
     ]
    }
   ],
   "source": [
    "nx=np.min(np.shape(X))\n",
    "ny=np.min(np.shape(y))\n",
    "print(X.shape)\n",
    "nh=3\n",
    "nl=2\n",
    "print(\"Size of input layer: \"+str(nx))\n",
    "print(\"Size of output layer: \"+str(ny))\n",
    "print(\"Size of hidden units in each layer: \"+str(nh))\n",
    "print(\"No of hidden layers: \"+str(nl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_params(nx,nh,ny):\n",
    "    \n",
    "    W1=np.random.randn(nh,nx)*0.01\n",
    "    b1=np.zeros((nh,1))\n",
    "    W2=np.random.randn(ny,nh)*0.01\n",
    "    b2=np.zeros((ny,1))\n",
    "    \n",
    "    \n",
    "    assert (W1.shape == (nh, nx))\n",
    "    assert (b1.shape == (nh, 1))\n",
    "    assert (W2.shape == (ny, nh))\n",
    "    assert (b2.shape == (ny, 1))\n",
    "    \n",
    "    params={\"W1\":W1,\"b1\":b1,\"W2\":W2,\"b2\":b2}\n",
    "    \n",
    "    return params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "params=initialise_params(nx,nh,ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(X,params):\n",
    "    \n",
    "    W1=params[\"W1\"]\n",
    "    b1=params[\"b1\"]\n",
    "    W2=params[\"W2\"]\n",
    "    b2=params[\"b2\"]\n",
    "    \n",
    "    Z1=np.dot(W1,X)\n",
    "    A1=np.tanh(Z1)\n",
    "    Z2=np.dot(W2,A1)\n",
    "    A2=sig(Z2)\n",
    "    \n",
    "    cache={\"Z1\":Z1,\"A1\":A1,\"Z2\":Z2,\"A2\":A2}\n",
    "    \n",
    "    return A2,cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2,cache=forward_prop(X,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(y,A2):\n",
    "    \n",
    "    m=np.max(y.shape)\n",
    "        \n",
    "    c1=np.dot(y,(np.log(A2)).T)\n",
    "    c2=np.dot((1-y),(np.log(1-A2)).T)\n",
    "    cost = -((c1+c2)/m)\n",
    "    \n",
    "    cost = np.squeeze(cost) \n",
    "    return (np.sum(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931819452494056\n"
     ]
    }
   ],
   "source": [
    "cost=compute_cost(y,A2)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(y,params,cache,X):\n",
    "    \n",
    "    W1=params[\"W1\"]\n",
    "    b1=params[\"b1\"]\n",
    "    W2=params[\"W2\"]\n",
    "    b2=params[\"b2\"]\n",
    "    \n",
    "    m=np.max(y.shape)\n",
    "    \n",
    "    A1=cache[\"A1\"]\n",
    "    A2=cache[\"A2\"]\n",
    "    \n",
    "    dZ2 = A2-y\n",
    "    dW2 = np.dot(dZ2,A1.T)/m\n",
    "    db2 = np.sum(dZ2,axis=1,keepdims=True)/m\n",
    "    dZ1 = np.dot(W2.T,dZ2)*(1-np.power(A1,2))\n",
    "    dW1 = np.dot(dZ1,X.T)/m\n",
    "    db1 = np.sum(dZ1,axis=1,keepdims=True)/m\n",
    "    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "    \n",
    "    return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads=back_prop(y,params,cache,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(grads,params,learning_rate=1.2):\n",
    "    \n",
    "    W1 = params[\"W1\"]\n",
    "    b1 = params[\"b1\"]\n",
    "    W2 = params[\"W2\"]\n",
    "    b2 = params[\"b2\"]\n",
    "    \n",
    "    dW1 = grads[\"dW1\"]\n",
    "    db1 = grads[\"db1\"]\n",
    "    dW2 = grads[\"dW2\"]\n",
    "    db2 = grads[\"db2\"]\n",
    "    \n",
    "    W1 = W1-(learning_rate*dW1)\n",
    "    b1 = b1-(learning_rate*db1)\n",
    "    W2 = W2-(learning_rate*dW2)\n",
    "    b2 = b2-(learning_rate*db2)\n",
    "    \n",
    "    \n",
    "    params = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return params\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.1\n",
    "params=update_params(grads,params,learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(X,y,nh,num_of_iters=10000,print_cost=False):\n",
    "    \n",
    "    nx=np.min(X.shape)\n",
    "    ny=np.min(y.shape)\n",
    "    \n",
    "    parameters=initialise_params(nx,nh,ny)\n",
    "    \n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    learning_rate=0.01\n",
    "    \n",
    "    for i in range(0,num_of_iters,1):\n",
    "        \n",
    "        A2,cache=forward_prop(X,parameters)\n",
    "        \n",
    "        cost=compute_cost(y,A2)\n",
    "        \n",
    "        grads=back_prop(y,parameters,cache,X)\n",
    "        \n",
    "        parameters=update_params(grads,parameters,learning_rate)\n",
    "        \n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693358\n",
      "Cost after iteration 1000: 0.659465\n",
      "Cost after iteration 2000: 0.290533\n",
      "Cost after iteration 3000: 0.237811\n",
      "Cost after iteration 4000: 0.225617\n",
      "Cost after iteration 5000: 0.220527\n",
      "Cost after iteration 6000: 0.217784\n",
      "Cost after iteration 7000: 0.231217\n",
      "Cost after iteration 8000: 0.228862\n",
      "Cost after iteration 9000: 0.226899\n",
      "Cost after iteration 10000: 0.225268\n",
      "Cost after iteration 11000: 0.223878\n",
      "Cost after iteration 12000: 0.222668\n",
      "Cost after iteration 13000: 0.221601\n",
      "Cost after iteration 14000: 0.220651\n",
      "Cost after iteration 15000: 0.219804\n",
      "Cost after iteration 16000: 0.219048\n",
      "Cost after iteration 17000: 0.218376\n",
      "Cost after iteration 18000: 0.217784\n",
      "Cost after iteration 19000: 0.217266\n",
      "Cost after iteration 20000: 0.216814\n",
      "Cost after iteration 21000: 0.216420\n",
      "Cost after iteration 22000: 0.216071\n",
      "Cost after iteration 23000: 0.215759\n",
      "Cost after iteration 24000: 0.215475\n",
      "Cost after iteration 25000: 0.215214\n",
      "Cost after iteration 26000: 0.214973\n",
      "Cost after iteration 27000: 0.214748\n",
      "Cost after iteration 28000: 0.214537\n",
      "Cost after iteration 29000: 0.214340\n",
      "Cost after iteration 30000: 0.214155\n",
      "Cost after iteration 31000: 0.213980\n",
      "Cost after iteration 32000: 0.213815\n",
      "Cost after iteration 33000: 0.213660\n",
      "Cost after iteration 34000: 0.213513\n",
      "Cost after iteration 35000: 0.213373\n",
      "Cost after iteration 36000: 0.213240\n",
      "Cost after iteration 37000: 0.213113\n",
      "Cost after iteration 38000: 0.212991\n",
      "Cost after iteration 39000: 0.212875\n",
      "Cost after iteration 40000: 0.212762\n",
      "Cost after iteration 41000: 0.212654\n",
      "Cost after iteration 42000: 0.212550\n",
      "Cost after iteration 43000: 0.212449\n",
      "Cost after iteration 44000: 0.212350\n",
      "Cost after iteration 45000: 0.212255\n",
      "Cost after iteration 46000: 0.212162\n",
      "Cost after iteration 47000: 0.212071\n",
      "Cost after iteration 48000: 0.211982\n",
      "Cost after iteration 49000: 0.211896\n",
      "Cost after iteration 50000: 0.211811\n",
      "Cost after iteration 51000: 0.211728\n",
      "Cost after iteration 52000: 0.211648\n",
      "Cost after iteration 53000: 0.211568\n",
      "Cost after iteration 54000: 0.211491\n",
      "Cost after iteration 55000: 0.211415\n",
      "Cost after iteration 56000: 0.211341\n",
      "Cost after iteration 57000: 0.211269\n",
      "Cost after iteration 58000: 0.211198\n",
      "Cost after iteration 59000: 0.211129\n",
      "Cost after iteration 60000: 0.211061\n",
      "Cost after iteration 61000: 0.210995\n",
      "Cost after iteration 62000: 0.210931\n",
      "Cost after iteration 63000: 0.210868\n",
      "Cost after iteration 64000: 0.210807\n",
      "Cost after iteration 65000: 0.210747\n",
      "Cost after iteration 66000: 0.210688\n",
      "Cost after iteration 67000: 0.210632\n",
      "Cost after iteration 68000: 0.210576\n",
      "Cost after iteration 69000: 0.210522\n",
      "Cost after iteration 70000: 0.210469\n",
      "Cost after iteration 71000: 0.210418\n",
      "Cost after iteration 72000: 0.210368\n",
      "Cost after iteration 73000: 0.210320\n",
      "Cost after iteration 74000: 0.210272\n",
      "Cost after iteration 75000: 0.210226\n",
      "Cost after iteration 76000: 0.210181\n",
      "Cost after iteration 77000: 0.210138\n",
      "Cost after iteration 78000: 0.210095\n",
      "Cost after iteration 79000: 0.210054\n",
      "Cost after iteration 80000: 0.210014\n",
      "Cost after iteration 81000: 0.209975\n",
      "Cost after iteration 82000: 0.209936\n",
      "Cost after iteration 83000: 0.209899\n",
      "Cost after iteration 84000: 0.209863\n",
      "Cost after iteration 85000: 0.209828\n",
      "Cost after iteration 86000: 0.209794\n",
      "Cost after iteration 87000: 0.209761\n",
      "Cost after iteration 88000: 0.209728\n",
      "Cost after iteration 89000: 0.209697\n",
      "Cost after iteration 90000: 0.209666\n",
      "Cost after iteration 91000: 0.209636\n",
      "Cost after iteration 92000: 0.209607\n",
      "Cost after iteration 93000: 0.209578\n",
      "Cost after iteration 94000: 0.209551\n",
      "Cost after iteration 95000: 0.209524\n",
      "Cost after iteration 96000: 0.209498\n",
      "Cost after iteration 97000: 0.209472\n",
      "Cost after iteration 98000: 0.209447\n",
      "Cost after iteration 99000: 0.209423\n"
     ]
    }
   ],
   "source": [
    "params=nn_model(X,y,nh,num_of_iters=100000,print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,params):\n",
    "    \n",
    "    A2, cache = forward_prop(X,params)\n",
    "    predictions = (A2>0.5)\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions mean = 0.8393672041375114\n",
      "Accuracy: 85%\n"
     ]
    }
   ],
   "source": [
    "predictions = predict(X,params)\n",
    "print(\"predictions mean = \" + str(np.mean(predictions)))\n",
    "\n",
    "print ('Accuracy: %d' % float((np.dot(y,predictions.T) + np.dot(1-y,1-predictions.T))/float(y.size)*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 3 hidden units: 85.57955582598113 %\n",
      "Accuracy for 4 hidden units: 85.57955582598113 %\n",
      "Accuracy for 5 hidden units: 85.57955582598113 %\n",
      "Accuracy for 20 hidden units: 85.57955582598113 %\n",
      "Accuracy for 22 hidden units: 85.57955582598113 %\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_sizes = [3, 4, 5, 20, 22, 50]\n",
    "for i, nh in enumerate(hidden_layer_sizes):\n",
    "    parameters = nn_model(X, y, nh, num_of_iters = 5000)\n",
    "    predictions = predict(X,parameters)\n",
    "    accuracy = float((np.dot(y,predictions.T) + np.dot(1-y,1-predictions.T))/float(y.size)*100)\n",
    "    print (\"Accuracy for {} hidden units: {} %\".format(nh, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
