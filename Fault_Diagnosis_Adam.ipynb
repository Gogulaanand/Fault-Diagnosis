{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fault Diagnosis_Adam.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gogulaanand/Fault-Diagnosis/blob/master/Fault_Diagnosis_Adam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "5xKj6p6CFrkR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import io\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "frKt0GEzFsw4",
        "colab_type": "code",
        "outputId": "600b6b83-23fd-4adc-ec17-67272c6e9410",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-16cdcae5-8f5b-4bde-bd2f-a16c5076625d\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-16cdcae5-8f5b-4bde-bd2f-a16c5076625d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving projdata.csv to projdata (6).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "meqqNOs3Fu9_",
        "colab_type": "code",
        "outputId": "b0598245-3811-412c-d8f2-801a20517085",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User uploaded file \"projdata.csv\" with length 132145 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pKAAeE5_Fw41",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(io.StringIO(uploaded['projdata.csv'].decode(\"utf-8\")),engine='python',sep=\",\")\n",
        "ds=df.sample(frac=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-GSeW4bTF0V6",
        "colab_type": "code",
        "outputId": "0c7e6a05-e66d-4a60-c830-b5b757f353fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "y=np.array(df[['Fault']])\n",
        "X=ds.as_matrix(columns=df.columns[1:])\n",
        "X=X.T\n",
        "y=y.T\n",
        "print(X.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 3287)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MrN7Lnqw-6em",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sig(x):\n",
        "  return 1.0/(1.0+np.exp(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FKu9d3Hf-6e7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "    return x*(x>0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DRHETxq8-6fR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def leaky_relu(x):\n",
        "    return x/(1+np.exp(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "snpF3eE8-6fe",
        "colab_type": "code",
        "outputId": "5738638d-e6d5-45f9-f863-65bf8d41db8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "nx=np.min(np.shape(X))\n",
        "ny=np.min(np.shape(y))\n",
        "nh=3\n",
        "nl=2\n",
        "layer_dims=[nx,nh,nh,ny]\n",
        "print(\"Size of input layer: \"+str(nx))\n",
        "print(\"Size of output layer: \"+str(ny))\n",
        "print(\"Size of hidden units in each layer: \"+str(nh))\n",
        "print(\"No of hidden layers: \"+str(nl))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input layer: 3\n",
            "Size of output layer: 1\n",
            "Size of hidden units in each layer: 3\n",
            "No of hidden layers: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6yfTIsPW-6fx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initialise_params(layer_dims):\n",
        "    \n",
        "    L=len(layer_dims)\n",
        "    \n",
        "    params={}\n",
        "    \n",
        "    for l in range(1,L,1):\n",
        "        params[\"W\"+str(l)]=np.random.randn(layer_dims[l],layer_dims[l-1])*np.sqrt(2/layer_dims[l-1])\n",
        "        params[\"b\"+str(l)]=np.zeros((layer_dims[l],1))\n",
        "            \n",
        "    for l in range(1,L):\n",
        "        assert (params[\"W\"+str(l)].shape == (layer_dims[l],layer_dims[l-1]))\n",
        "        assert (params[\"W\"+str(l)].shape == (layer_dims[l],layer_dims[l-1]))\n",
        "        \n",
        "    \n",
        "    return params\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dMwGIJXe-6f_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "params=initialise_params(layer_dims)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lUz-l8CK-6gR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def forward_prop(X,params):\n",
        "    \n",
        "    W1=params[\"W1\"]\n",
        "    b1=params[\"b1\"]\n",
        "    W2=params[\"W2\"]\n",
        "    b2=params[\"b2\"]\n",
        "    W3=params[\"W3\"]\n",
        "    b3=params[\"b3\"]\n",
        "    \n",
        "    Z1=np.dot(W1,X)+b1\n",
        "    A1=np.tanh(Z1)\n",
        "    Z2=np.dot(W2,A1)+b2\n",
        "    A2=np.tanh(Z2)\n",
        "    Z3=np.dot(W3,A2)+b3\n",
        "    A3=sig(Z3)\n",
        "    \n",
        "    cache={\"Z1\":Z1,\"A1\":A1,\"Z2\":Z2,\"A2\":A2,\"Z3\":Z3,\"A3\":A3}\n",
        "    \n",
        "    return A3,cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8UA2C9YA-6gv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "A3,cache=forward_prop(X,params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jrFXB22j-6g7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_cost(y,A3,params,lambd=0):\n",
        "    \n",
        "    m=np.max(y.shape)\n",
        "        \n",
        "    c1=np.dot(y,(np.log(A3)).T)\n",
        "    c2=np.dot((1-y),(np.log(1-A3)).T)\n",
        "    \n",
        "    w1=np.sum(np.square(params[\"W1\"]))\n",
        "    w2=np.sum(np.square(params[\"W2\"]))\n",
        "    w3=np.sum(np.square(params[\"W3\"]))\n",
        "    \n",
        "    c3=(lambd/(2*m))*(w1+w2+w3)\n",
        "    \n",
        "    cost = -((c1+c2)/m)+c3\n",
        "    \n",
        "    cost = np.squeeze(cost) \n",
        "    return (np.sum(cost))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S5YzZsaM-6hE",
        "colab_type": "code",
        "outputId": "404a332c-eef3-4d35-a4d8-c2ce077161f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "cost=compute_cost(y,A3,params,lambd=0)\n",
        "print(cost)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7896069605718027\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N0N1ZTNQCITW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def random_mini_batch(X,y,mini_batch_size=128):\n",
        "  \n",
        "  m=X.shape[1]\n",
        "  \n",
        "  \n",
        "  \n",
        "  permutation=list(np.random.permutation(m))      #to shuffle the x and y matrices\n",
        "  shuffled_X=X[:,permutation]\n",
        "  shuffled_Y=y[:,permutation].reshape((1,m))\n",
        "  \n",
        "\n",
        "  mini_batches=[]\n",
        "  \n",
        "  total_possible_mini_batches=math.floor(m/mini_batch_size)\n",
        "  \n",
        "  for k in range(total_possible_mini_batches):\n",
        "    \n",
        "    mini_batch_X=shuffled_X[:,(mini_batch_size*k):(mini_batch_size*(k+1))]\n",
        "    mini_batch_Y=shuffled_Y[:,(mini_batch_size*k):(mini_batch_size*(k+1))]\n",
        "    \n",
        "    mini_batch=(mini_batch_X,mini_batch_Y)\n",
        "   \n",
        "    mini_batches.append(mini_batch)\n",
        "    \n",
        "  \n",
        "  if m%mini_batch_size!=0:\n",
        "    \n",
        "    mini_batch_X=shuffled_X[:,total_possible_mini_batches*mini_batch_size:m]\n",
        "    mini_batch_Y=shuffled_Y[:,total_possible_mini_batches*mini_batch_size:m]\n",
        "   \n",
        "    mini_batch=(mini_batch_X,mini_batch_Y)\n",
        "    mini_batches.append(mini_batch)\n",
        "  \n",
        "    \n",
        "  return mini_batches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YhUBFUfOOzGx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mini_batches=random_mini_batch(X,y,mini_batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nBIkRC0N-6hT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def backward_prop(y,params,cache,X,lambd=0):\n",
        "    \n",
        "    W1=params[\"W1\"]\n",
        "    b1=params[\"b1\"]\n",
        "    W2=params[\"W2\"]\n",
        "    b2=params[\"b2\"]\n",
        "    W3=params[\"W3\"]\n",
        "    b3=params[\"b3\"]\n",
        "    \n",
        "    m=np.max(y.shape)\n",
        "    \n",
        "    A1=cache[\"A1\"]\n",
        "    A2=cache[\"A2\"]\n",
        "    A3=cache[\"A3\"]\n",
        "    \n",
        "    \n",
        "    dZ3 = A3-y\n",
        "    dW3 = np.dot(dZ3,A3.T)/m+((lambd/m)*W3)\n",
        "    db3 = np.sum(dZ3,axis=1,keepdims=True)/m\n",
        "    dZ2 = np.dot(W3.T,dZ3)*(1-np.power(A2,2))\n",
        "    dW2 = np.dot(dZ2,A2.T)/m+((lambd/m)*W2)\n",
        "    db2 = np.sum(dZ2,axis=1,keepdims=True)/m\n",
        "    dZ1 = np.dot(W2.T,dZ2)*(1-np.power(A1,2))\n",
        "    dW1 = np.dot(dZ1,X.T)/m+((lambd/m)*W1)\n",
        "    db1 = np.sum(dZ1,axis=1,keepdims=True)/m\n",
        "    \n",
        "    grads = {\"dW1\": dW1,\n",
        "             \"db1\": db1,\n",
        "             \"dW2\": dW2,\n",
        "             \"db2\": db2,\n",
        "             \"dW3\": dW3,\n",
        "             \"db3\": db3}\n",
        "    \n",
        "    return grads\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c4IBTVLs6w1_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "grads=backward_prop(y,params,cache,X,lambd=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gv97BAisEhRQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initialise_adam_params(params):\n",
        "  \n",
        "  W1=params[\"W1\"]\n",
        "  b1=params[\"b1\"]\n",
        "  W2=params[\"W2\"]\n",
        "  b2=params[\"b2\"]\n",
        "  W3=params[\"W3\"]\n",
        "  b3=params[\"b3\"]\n",
        "  \n",
        "  v={}\n",
        "  s={}\n",
        "  \n",
        "  for l in range(len(params)//2):\n",
        "    \n",
        "    v[\"dW\"+str(l+1)]=np.zeros(params[\"W\"+str(l+1)].shape)\n",
        "    v[\"db\"+str(l+1)]=np.zeros(params[\"b\"+str(l+1)].shape)\n",
        "    s[\"dW\"+str(l+1)]=np.zeros(params[\"W\"+str(l+1)].shape)\n",
        "    s[\"db\"+str(l+1)]=np.zeros(params[\"b\"+str(l+1)].shape)\n",
        "                                                    \n",
        "  return v,s\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JPhcmr2zORe7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "v,s=initialise_adam_params(params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mKRtBSLkOtje",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def update_params_with_adam(params,v,s,grads,learning_rate=0.005,beta1=0.9,beta2=0.999,epsilon=1e-7):\n",
        "  \n",
        "  L=len(params)//2\n",
        "  v_corrected={}\n",
        "  s_corrected={}\n",
        "  \n",
        "  for l in range(L):\n",
        "    \n",
        "    v[\"dW\"+str(l+1)]=beta1*v[\"dW\"+str(l+1)]+(1-beta1)*grads[\"dW\"+str(l+1)]\n",
        "    v[\"db\"+str(l+1)]=beta1*v[\"db\"+str(l+1)]+(1-beta1)*grads[\"db\"+str(l+1)]\n",
        "    \n",
        "    v_corrected[\"dW\"+str(l+1)]=v[\"dW\"+str(l+1)]/(1-(beta1**2))\n",
        "    v_corrected[\"db\"+str(l+1)]=v[\"db\"+str(l+1)]/(1-beta1**2)\n",
        "    \n",
        "    s[\"dW\"+str(l+1)]=beta2*s[\"dW\"+str(l+1)]+(1-beta2)*(grads[\"dW\"+str(l+1)]**2)\n",
        "    s[\"db\"+str(l+1)]=beta2*s[\"db\"+str(l+1)]+(1-beta2)*(grads[\"db\"+str(l+1)]**2)\n",
        "    \n",
        "    s_corrected[\"dW\"+str(l+1)]=s[\"dW\"+str(l+1)]/(1-beta2**2)\n",
        "    s_corrected[\"db\"+str(l+1)]=s[\"db\"+str(l+1)]/(1-beta2**2)\n",
        "    \n",
        "    \n",
        "    params[\"W\"+str(l+1)] = params[\"W\"+str(l+1)]-(learning_rate*(v_corrected[\"dW\"+str(l+1)]/np.sqrt(s_corrected[\"dW\"+str(l+1)]+epsilon)))\n",
        "    params[\"b\"+str(l+1)] = params[\"b\"+str(l+1)]-(learning_rate*(v_corrected[\"db\"+str(l+1)]/np.sqrt(s_corrected[\"db\"+str(l+1)]+epsilon)))\n",
        "                                               \n",
        "  return params,v,s \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nzUzuu55SKQi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "params,v,s=update_params_with_adam(params,v,s,grads,learning_rate=0.005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q4DFrfavzHOU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def nn_model(X,y,layer_dims,learning_rate=0.005,mini_batch_size=128,num_of_epochs=5000,beta1=0.9,beta2=0.999,epsilon=1e-8,print_cost=True):\n",
        "  \n",
        "  \n",
        "  params=initialise_params(layer_dims)\n",
        "  \n",
        "  costs=[]\n",
        "  \n",
        "  v,s=initialise_adam_params(params)\n",
        "  \n",
        "  for i in range(num_of_epochs):\n",
        "    \n",
        "    mini_batches=random_mini_batch(X,y,mini_batch_size)\n",
        "    \n",
        "    for batch in mini_batches:\n",
        "      \n",
        "      (X_batch,Y_batch)=batch\n",
        "      \n",
        "      a3,caches=forward_prop(X_batch,params)\n",
        "      \n",
        "      cost=compute_cost(Y_batch,a3,params)\n",
        "\n",
        "      grads=backward_prop(Y_batch,params,caches,X_batch,lambd=0)\n",
        "      \n",
        "      params,v,s=update_params_with_adam(params,v,s,grads,learning_rate,beta1,beta2,epsilon)\n",
        "      \n",
        "      \n",
        "    if print_cost and i%500==0:\n",
        "      print(\"cost after epoch %i: %f\" %(i,cost))\n",
        "    \n",
        "    if print_cost and i%100==0:\n",
        "      costs.append(cost)\n",
        "\n",
        "  return params"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bMWzPZrj2g4P",
        "colab_type": "code",
        "outputId": "32649aa1-2f39-40b9-ad40-060e2fec0c0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 705
        }
      },
      "cell_type": "code",
      "source": [
        "params=nn_model(X,y,layer_dims,learning_rate=0.1,mini_batch_size=128,num_of_epochs=5000)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cost after epoch 0: 0.813141\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in log\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cost after epoch 500: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cost after epoch 1000: nan\n",
            "cost after epoch 1500: nan\n",
            "cost after epoch 2000: nan\n",
            "cost after epoch 2500: nan\n",
            "cost after epoch 3000: nan\n",
            "cost after epoch 3500: nan\n",
            "cost after epoch 4000: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-eda138d516f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer_dims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_of_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-fc758d80fb8b>\u001b[0m in \u001b[0;36mnn_model\u001b[0;34m(X, y, layer_dims, learning_rate, mini_batch_size, num_of_epochs, beta1, beta2, epsilon, print_cost)\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0mgrads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcaches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate_params_with_adam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-065e6121ae52>\u001b[0m in \u001b[0;36mupdate_params_with_adam\u001b[0;34m(params, v, s, grads, learning_rate, beta1, beta2, epsilon)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0ms_corrected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dW\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dW\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0ms_corrected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"db\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"db\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "eZqOrjk23liT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(X,params):\n",
        "  \n",
        "  A3,cache=forward_prop(X,params)\n",
        "  \n",
        "  predictions=(A3>0.5)\n",
        "  \n",
        "  return predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KKVPqsYT3xyG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions=predict(X,params)\n",
        "\n",
        "print(\"predictions mean = \"+str(np.mean(predictions)))\n",
        "\n",
        "print(\"Accuracy: %d\"%float((np.dot(y,predictions.T)+np.dot(1-y,1-predictions.T))/float(y.size)*100)+\"%\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T2FB7JaF-6i5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hidden_layer_sizes = [3, 4, 5, 15, 16, 17, 18, 19, 20]\n",
        "for i, nh in enumerate(hidden_layer_sizes):\n",
        "    layer_dims=[nx,nh,nh,ny]\n",
        "    parameters = nn_model(X, y,layer_dims)\n",
        "    predictions = predict(X,parameters)\n",
        "    accuracy = float((np.dot(y,predictions.T) + np.dot(1-y,1-predictions.T))/float(y.size)*100)\n",
        "    print (\"Accuracy for {} hidden units: {} %\".format(nh, accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}